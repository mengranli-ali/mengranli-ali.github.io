---
layout: post
title: "Python Data Science: How to automatically collect data?"
subtitle: 'How to collect data sources?' 
author: "Mengran"
header-style: text
tags:
  - Python
  - Data Science
  - Data Analysis
  - Data Collection
---

### Data Collection

**Multiple Data Sources**

一个数据的走势，是由多个维度影响的。

我们需要通过多源的数据采集，收集到尽可能多的数据维度，同时保证数据的质量，这样才能得到高质量的数据挖掘结果。

**Four types of data sources 四种数据源**
- Open Data Sources 开放数据源: 一般是针对行业的数据库，来自政府机构或企业。
- Scratching 爬虫抓取: 一般是针对特定的网站或 App。
- Sensor 传感器: 基本上采集的是物理信息。比如图像、视频、或者某个物体的速度、热度、压强等。
- Log 日志采集: 这个是统计用户的操作。我们可以在前端进行埋点，在后端进行脚本收集、统计，来分析网站的访问情况，以及使用瓶颈等。

#### Open Resources

开放数据源可以从两个维度来考虑:
- 一个是单位的维度，比如政府、企业、高校；
- 一个就是行业维度，比如交通、金融、能源等领域。

#### Python Scratching

爬虫抓取应该属于最常见的需求，比如你想要餐厅的评价数据。

当然这里要注重版权问题，而且很多网站也是有反爬机制的。

最直接的方法就是使用 Python 编写爬虫代码，当然前提是你需要会 Python 的基本语法。除此之外，PHP 也可以做爬虫，只是功能不如 Python 完善，尤其是涉及到多线程的操作。

**Process of Scratching 爬虫过程:**
- 使用 Requests 爬取内容。我们可以使用 Requests 库来抓取网页信息。Requests 库可以说是 Python 爬虫的利器，也就是 Python 的 HTTP 库，通过这个库爬取网页中的数据，方便节约。
- 使用 XPath 解析内容。XPath 是 XML Path 的缩写，也就是 XML 路径语言。它是一种用来确定 XML 文档中某部分位置的语言，在开发中经常用来当作小型查询语言。XPath 可以通过元素和属性进行位置索引。
- 使用 Pandas 保存数据。Pandas 是让数据分析工作变得更加简单的高级数据结构，我们可以用 Pandas 保存爬取的数据。最后通过 Pandas 再写入到 XLS 或者 MySQL 等数据库中。

当然做 Python 爬虫还有很多利器，比如 Selenium，PhantomJS，或者用 Puppeteer 这种无头模式。

#### Log

**日志**就是日记的意思，它记录了用户访问网站的全过程：
- 哪些人在什么时间
- 通过什么渠道（比如搜索引擎、网址输入）来过，都执行了哪些操作；
- 系统是否产生了错误；
- 甚至包括用户的 IP、HTTP 请求的时间，用户代理等。
  
**这些日志数据可以被写在一个日志文件中，也可以分成不同的日志文件，比如访问日志、错误日志等。**

**日志采集最大的作用:** 
- 通过分析用户访问情况，提升系统的性能，从而提高系统承载量。
- 及时发现系统承载瓶颈，也可以方便技术人员基于用户实际的访问情况进行优化。

**日志采集可以分两种形式:**
- 通过 Web 服务器采集，例如 httpd、Nginx、Tomcat 都自带日志记录功能。同时很多互联网企业都有自己的海量数据采集工具，多用于系统日志采集，如 Hadoop 的 Chukwa、Cloudera 的 Flume、Facebook 的 Scribe 等，这些工具均采用分布式架构，能够满足每秒数百 MB 的日志数据采集和传输需求。
- 自定义采集用户行为，例如用 JavaScript 代码监听用户的行为、AJAX 异步请求后台记录日志等。

**Event Tracking 埋点**

埋点是日志采集的关键步骤, 埋点就是在有需要的位置采集相应的信息，进行上报。

比如某页面的访问情况，包括用户信息、设备信息；或者用户在页面上的操作行为，包括时间长短等。这就是埋点，每一个埋点就像一台摄像头，采集用户行为数据，将数据进行多维度的交叉分析，可真实还原出用户使用场景，和用户使用需求。

使用前端埋点，你可以通过JavaScript获取一些信息，包括页面标题，访问的URL，浏览器的语言，显示的颜色深度，分辨率等。同时你还可以通过埋点获取想要监测的业务数据。

**如何进行埋点呢？**

埋点就是在你需要统计数据的地方植入统计代码，当然植入代码可以自己写，也可以使用第三方统计工具。

使用第三方的工具，比如友盟、Google Analysis、Talkingdata 等。他们都是采用前端埋点的方式，然后在第三方工具里就可以看到用户的行为数据。

但如果我们想要看到更深层的用户操作行为，就需要进行自定义埋点。


Example:

**预测比特币的未来走势，可以从以下维度抓取数据:**
- 认知度：社会对比特币的认可，抓取百度指数、谷歌搜索量、微博数据等
- 比特币依赖的技术：作为数字货币，核心技术的完善和认可度占比重较大，可以从区块链相关技术网站爬取数据，也可以从微博爬取（微博也是技术人活跃的交流平台）
- 供给平衡：比特币虽说是一种数字货币，但仍逃脱不掉是一种商品的本质，商品必然受市场平衡调节影响，所以爬取买入量、抛售量还有历史价格也是一种预测维度
- 政府政策：政府政策的影响占很大比重，若国家出台政策强制打压或者支持，那么对价格的影响起了根本性作用，所以需要爬取相关的新闻
- 竞争数字货币：作为一种商品，必然要考虑竞争品的相关情况，需要抓取其它数字货币相关信息如其它货币的价格、交易量。资本在流入其它市场的时候，与之对应的竞品必然会受影响。抓取数据途径：其它货币交易平台

